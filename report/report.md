# Web and Social Information Extraction Project
**Luca Moschella** (1594551)
**Federica Spini** (*1588482*)

---

## Introduction
# CI


L’introduzione e le conclusioni per abitudine le farei alla fine, tanto è una specie di punto della situazione
## Reading the dataset
The first thing we had to decide in our project has been how to read the dataset and organize the data in a Java Program. This hasn’t been a trivial task, because from this would depend all the rest of the project. So, let’s talk now about wikimid, s21, s22 and s23.
## Dataset description
The datasets together describe twitter user thank to their relation with other “Twitter objects” that we modelled with a java class. In general we have an ObjectModel abstract class that gives every object an id and make it serializable. This is important, because we have a lot of data and in this way we can save step by step informations into json documents, that we can read without the need of processing everything every time.
The twitter object class is extended by every
$$
\alpha = \sum_{i =3}^{n} ohoh
$$
##  Dataset organization in the project
## Categorization of the wikimid users
## Clusterization of the wikimid users
## Evaluating the clusters
## Twitter Information Extraction
## Inserting new Twitter Users in the clusters
## Reccommandantion system
## Conclusions

- [ ] ciao
